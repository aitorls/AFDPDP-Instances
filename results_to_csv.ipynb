{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e33774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:06:44.402103Z",
     "start_time": "2025-05-05T17:06:44.399907Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import xlabel\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e784bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:06:44.449128Z",
     "start_time": "2025-05-05T17:06:44.443101Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_solutions(output_dir: str) -> List[Dict]:\n",
    "    file_names = os.listdir(output_dir)\n",
    "    bh_files = [f for f in file_names if f.startswith(\"BH_\")]\n",
    "    urjc_files = [f for f in file_names if f.startswith(\"URJC_\")]\n",
    "    upv_delay_files = [f for f in file_names if f.startswith(\"UPVD_\")]\n",
    "    ws_delay_files = [f for f in file_names if f.startswith(\"WSD_\")]\n",
    "    #urjc_files = [f for f in file_names if f not in upv_files+bh_files+ws_files and not f.startswith(\"WS_iterations_\")]\n",
    "    \n",
    "\n",
    "    urjc_solutions = load_json_solutions([os.path.join(output_dir, f) for f in urjc_files])\n",
    "    bh_solutions = load_json_solutions([os.path.join(output_dir, f) for f in bh_files])\n",
    "    upv_delay_solutions = load_json_solutions([os.path.join(output_dir, f) for f in upv_delay_files])\n",
    "    ws_delay_solutions = load_json_solutions([os.path.join(output_dir, f) for f in ws_delay_files])\n",
    "\n",
    "    return urjc_solutions, bh_solutions, upv_delay_solutions, ws_delay_solutions\n",
    "\n",
    "def load_json_solutions(file_paths: List[str]) -> List[Dict]:\n",
    "    return [json.load(open(path)) for path in file_paths]\n",
    "\n",
    "def get_best_solution(solutions: List[Dict]) -> Dict:\n",
    "    return min(solutions, key=lambda x: x['computational_time'])\n",
    "    #return min(solutions, key=lambda x: x['cost'])\n",
    "\n",
    "def extract_number_by_string(input_string: List[str], pattern : str) -> List[int]:\n",
    "    rqt_numbers = []\n",
    "    groups_letters = input_string.split(\"_\")\n",
    "    if not pattern:\n",
    "        return groups_letters[-1]\n",
    "    \n",
    "    for group in groups_letters:\n",
    "        if pattern in group:\n",
    "            end = group.find(pattern)\n",
    "            return int(group[:end])\n",
    "\n",
    "    return \"Not Found\"\n",
    "\n",
    "def extract_results(results_json, exp_graph, f, algorithm):\n",
    "    \n",
    "        used_vehicles_costs = [cost for cost in results_json[\"costs_routes\"].values() if cost > 0]\n",
    "        \n",
    "        return {\n",
    "            \"graph\" : exp_graph,\n",
    "            \"instance\" : f,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"requests\": extract_number_by_string(results_json[\"instance_name\"], \"RQT\"),\n",
    "            \"robots\" : extract_number_by_string(results_json[\"instance_name\"], \"HR\"),\n",
    "            \"capacity\" : extract_number_by_string(results_json[\"instance_name\"], \"Q\"),\n",
    "            \"demand\" : extract_number_by_string(results_json[\"instance_name\"], \"q\"),\n",
    "            \"num_instance\" : extract_number_by_string(results_json[\"instance_name\"], None),\n",
    "            \"isBigTW\": bool(\"bigTW\" in results_json[\"instance_name\"]),\n",
    "            \"cost\": results_json['cost'],\n",
    "            \"time\": results_json['max_time'],\n",
    "            \"distance\" : results_json['distance_travelled'],\n",
    "            \"used_vehicles\": len(used_vehicles_costs),\n",
    "            \"used_max\": max(used_vehicles_costs),\n",
    "            \"used_min\": min(used_vehicles_costs),\n",
    "            \"used_mean\": sum(used_vehicles_costs) / len(used_vehicles_costs),\n",
    "            \"computational_time\" : results_json['computational_time'],\n",
    "            \"delay\" : results_json.get('delay', 0),\n",
    "            \"delay_cost\" : results_json.get('delay_cost', 0)\n",
    "        }\n",
    "\n",
    "def add_empty_results(exp_graph, f, algorithm):\n",
    "\n",
    "        return {\n",
    "            \"graph\" : exp_graph,\n",
    "            \"instance\" : f,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"requests\": extract_number_by_string(f, \"RQT\"),\n",
    "            \"robots\" : extract_number_by_string(f, \"HR\"),\n",
    "            \"capacity\" : extract_number_by_string(f, \"Q\"),\n",
    "            \"demand\" : extract_number_by_string(f, \"q\"),\n",
    "            \"num_instance\" : extract_number_by_string(f, None),\n",
    "            \"isBigTW\": bool(\"bigTW\" in f),\n",
    "            \"cost\": None,\n",
    "            \"time\": None,\n",
    "            \"distance\" : None,\n",
    "            \"used_vehicles\": None,\n",
    "            \"used_max\": None,\n",
    "            \"used_min\": None,\n",
    "            \"used_mean\": None,\n",
    "            \"computational_time\" : None,\n",
    "            \"delay\" : None,\n",
    "            \"delay_cost\" : None\n",
    "        }\n",
    "        \n",
    "def add_results_or_empty(all_results: list, solutions, exp_graph, experiment, algorithm):\n",
    "    try:\n",
    "        best_f = get_best_solution(solutions)\n",
    "        if algorithm in [\"WSHeuristic\", \"Heuristic\"] and best_f[\"invalid\"]:\n",
    "            raise ValueError(\"The solution is invalid.\")\n",
    "        results = extract_results(best_f, exp_graph, experiment, algorithm)\n",
    "        all_results.append(results)\n",
    "        return True\n",
    "    except (KeyError, ValueError):\n",
    "        results = add_empty_results(exp_graph, experiment, algorithm)\n",
    "        all_results.append(results)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e1a49d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:06:50.152684Z",
     "start_time": "2025-05-05T17:06:48.240244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_8\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_7\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_3\n",
      "Error: No MILP solutions found for asymmetric_grid/6HR_6Q_50RQT_2q_bigTW_8\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_6\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_2\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_0\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_1\n",
      "Error: No MILP solutions found for asymmetric_grid/6HR_6Q_50RQT_2q_bigTW_2\n",
      "Error: No MILP solutions found for asymmetric_grid/6HR_6Q_50RQT_2q_bigTW_5\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_4\n",
      "Error: No MILP solutions found for asymmetric_grid/9HR_6Q_50RQT_2q_bigTW_9\n",
      "Error: No MILP solutions found for asymmetric_grid/6HR_6Q_50RQT_2q_bigTW_3\n",
      "Error: No MILP solutions found for symmetric_grid/6HR_6Q_50RQT_2q_bigTW_0\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_8\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_7\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_3\n",
      "Error: No MILP solutions found for symmetric_grid/6HR_6Q_50RQT_2q_bigTW_8\n",
      "Error: No MILP solutions found for symmetric_grid/6HR_6Q_50RQT_2q_bigTW_1\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_6\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_2\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_0\n",
      "Error: No MILP solutions found for symmetric_grid/6HR_6Q_50RQT_2q_bigTW_2\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_3\n",
      "Error: No MILP solutions found for symmetric_grid/6HR_6Q_50RQT_2q_bigTW_6\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_4\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_9\n",
      "Error: No MILP solutions found for symmetric_grid/9HR_6Q_50RQT_2q_bigTW_5\n"
     ]
    }
   ],
   "source": [
    "results_name_file = \"results.csv\"\n",
    "experiments_graph = [\"random\", \"mountain\", \"asymmetric_grid\", \"symmetric_grid\"] \n",
    "\n",
    "\n",
    "all_results = []\n",
    "fail_experiments = []\n",
    "for exp_graph in experiments_graph:\n",
    "    path = f\"{exp_graph}\" # Path to the folder containing the experiments\n",
    "    exp_files = listdir(path)\n",
    "    for experiment in exp_files:\n",
    "        urjc_solutions, bh_solutions, upv_delay_solutions, ws_delay_solutions = load_solutions(f\"{path}/{experiment}/output\")\n",
    "\n",
    "        if not add_results_or_empty(all_results, urjc_solutions, exp_graph, experiment, \"MILP\"):\n",
    "            print(f\"Error: No MILP solutions found for {path}/{experiment}\")\n",
    "            fail_experiments.append(f\"{path}/MILP/{experiment}\")\n",
    "            \n",
    "        \n",
    "        if not add_results_or_empty(all_results, bh_solutions, exp_graph, experiment, \"SCFI\"):\n",
    "            print(f\"Error: No Base Heuristic solutions found for {path}/{experiment}\")\n",
    "            fail_experiments.append(f\"{path}/SCFI/{experiment}\")\n",
    "            \n",
    "    \n",
    "        \n",
    "        if not add_results_or_empty(all_results, upv_delay_solutions, exp_graph, experiment, \"MCFI\"):\n",
    "            print(f\"Error: No UPV Delay solutions found for {path}/{experiment}\")\n",
    "            fail_experiments.append(f\"{path}/MCFI/{experiment}\")\n",
    "\n",
    "        if not add_results_or_empty(all_results, ws_delay_solutions, exp_graph, experiment, \"WS-MILP\"):\n",
    "            print(f\"Error: No WS Delay solutions found for {path}/{experiment}\")\n",
    "            fail_experiments.append(f\"{path}/WS-MILP/{experiment}\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(results_name_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a08bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
